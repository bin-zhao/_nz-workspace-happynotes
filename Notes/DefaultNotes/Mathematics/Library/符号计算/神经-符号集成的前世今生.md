
---

# 神经-符号集成的前世今生

原创 Sienna 深蓝AI _2024年03月05日 09:18_ _北京_

![[46c46b1c0daab8a3189a33f91a5cc463_MD5.webp]]

▲图1｜神经-符号集成的主要目的是利用神经网络捕捉符号和逻辑推理（来源@pixabay）©️【深蓝AI】

  

近十年来，深度学习已成为人工智能领域进步的核心动力，引发了广泛关注。尽管深度学习在人工智能领域占据着主导地位，但人们对它的概念与涉及领域的了解依旧很模糊。实际上，人工智能、机器学习与深度学习三方的关系可以简单概括为：

  

> 人工智能（Artificial Intelligence, AI）⊃机器学习（Machine Learning, ML）⊃深度学习（Deep Learning, DL）

  

尽管深度学习的广泛成功和普及已经在很大程度上超越了先前的技术，但那些传统技术依然能为我们带来一些独特而有趣的功能。在本文中，我们将深入挖掘原始的符号人工智能理论，并探讨如何将其与深度学习巧妙地结合，以便充分利用这两种看似格格不入、甚至在某些方面相互冲突的学习与AI方法的长处。

  

![[70720e2ea847a90db4253bcdf0349c68_MD5.webp]]

##   

## 从历史的角度审视，AI领域的的符号（symbolic）流派与子符号（sub-symbolic）流派都沿着各自独立的轨迹发展，每个领域都专注于其特定的、往往相对狭隘的问题集。

##   

## 在初期，研究人员更倾向于采用离散的符号方法来探索人工智能的奥秘，他们的目标广泛而深远，从知识表示、逻辑推理与规划，到自动定理证明等多个领域。

##   

## 虽然符号AI涵盖了多种多样的具体技术，但其核心大多建立在数理逻辑（mathematical logic）的基础之上。如下图所示，一个苹果可以通过其各个层级部件的逻辑关系来表示。数理逻辑不仅为众多符号操作的基本概念提供了恰当且“整洁”的表达方式，并且是设计大型知识库、专家和生产规则系统，以及开发专用编程语言的重要工具。

  

![[3b8f06322bd5d01ece2643e50bf62006_MD5.webp]]

▲图2｜符号流派如何表示一个苹果（来源@MIT-IBM Watson AI Lab）©️【深蓝AI】

  

通过运用这种形式，人们能够系统地构建和推理，使得人工智能系统更加精准和高效。

  

随后，符号逻辑表示法在机器学习领域也得到了广泛的应用，尤其是以归纳逻辑编程（Inductive Logic Programming, ILP）的形式出现。这种方法将专家知识融入学习模型和算法中，展现出了强大的能力。

  

![[115947c7d7e5010e819cc5fa7348b2a0_MD5.webp]]

▲图3｜归纳逻辑编程为机器学习与逻辑编程的交叉©️【深蓝AI】

  

基于逻辑的AI方法的主要优势在于其对人类的透明度、演绎推理的能力、专家知识的融入以及从小数据中进行结构化归纳的特点。然而，它也存在着一些显著的缺点，如计算复杂性高、难以处理现实世界中的噪声问题、以及处理数值和不确定性的挑战。

  

正因为这些缺点，大多数符号AI方法在实际应用中并未得到广泛采用，相较于今天所见的深度学习方法，它们更多停留在理论层面。

  

与此同时，随着计算能力和可用数据量的不断提升，另一种AI方法开始崭露头角。统计机器学习最初仅限于回归和分类等“狭义”问题，但随着时间的推移，它开始渗透到更广泛的AI领域。

  

随着深度学习时代的到来，这一趋势更加明显。深度学习领域完全被亚符号、连续、分布式表征所主导，这使得符号人工智能的故事似乎告一段落。

  

**■1.1 深度学习的兴起**

  

神经网络，这一术语在深度学习崭露头角之前便已存在。

  

其来源最早可以追溯到1943年，当时首个计算神经元问世，为神经网络的发展奠定了基础。进入20世纪80和90年代，将计算神经元层层叠加以构建复杂网络的方法逐渐流行起来。然而，在那个时期，神经网络在与其他更成熟、更有理论支撑的学习模型，如支持向量机（SVM）等的竞争中，常常处于劣势地位。

  

2010年，神经网络在提升语音识别任务准确率方面取得了迅速的经验性成功，这一重大突破标志着现代深度学习时代的开端。随后的不久，神经网络在计算机视觉领域也取得了类似的卓越成就，进一步巩固了其在人工智能领域的重要地位。

  

鉴于神经网络在机器感知标准基准上展现出的强大效果，研究人员开始逐渐放弃为SVM所设计的高级特征提取流程，而是转向采纳新兴的神经架构工艺。

  

随着这一趋势的转变，许多源自80年代和90年代的神经网络变体再次获得了人们的关注或被引入新的应用领域。GPU并行处理能力的显著增强，以及可用数据量的持续增长，为深度学习在感知机器学习领域的稳步崛起奠定了坚实基础。

  

![[6955ceea621abf1dfb1215ba6cd6b9f5_MD5.webp]]

▲图4｜摄取张量样本的卷积神经网络中共享权重的典型（对称）模式（来源@TDS）©️【深蓝AI】

  

### **■1.2 可微分编程**

###   

### 在大量实验的推动下，深度学习已经从最初的生物脑启发感知智能模型，逐渐转变为一种“实践可行”的工程方法。这种转变本质上使深度学习演变成了一种极其通用的技术——即利用梯度下降来优化几乎任意嵌套函数的参数。

因此，很多人倾向于将这一领域重新命名为“可微分编程（Differentiable Programming）”。这一观点为开发新算法、新技巧和新调整提供了广阔的空间，这些创新以各种易于记忆的名称被引入到基础功能模块中，而这些模块依然主要由基础线性代数运算的各种组合构成。

  

然而，随着这种演变的深入，我们也开始观察到深度学习社区对结构化、类似程序的符号表示法重新产生了兴趣。事实上，现代神经架构的发展已经超越了简单地在更大数据集上堆叠更多全连接层的模式，而是在可微分程序中融入了以某种结构偏差形式存在的先验知识增量。这样的设计使得模型能够更好地完成需要更高层次抽象的复杂任务。

  

至于在模型中加入多少先验知识，一直是人工智能领域研究人员热议的话题。

  

![[51c897d15f3be5b5c72ea34c757567b2_MD5.webp]]

  

随着感知水平的逐渐饱和，深度学习正进一步扩展到更加多元化的领域，这些领域最初曾被视为高度符号化的。从游戏和语言建模开始，深度学习已经逐渐渗透到编程、算法推理，甚至定理证明等领域。

  

尽管现在经过足够的调整，大型神经网络似乎可以解决各种AI问题，但我们依旧不能忽视神经网络本身所缺乏的一些基本功能。这些功能包括捕捉关系和组成结构、抽象概念的符号推理、鲁棒性和透明度等，这些都是被广泛认为是AI系统的核心要素。

  

与此同时，基于逻辑的方法自然具备这些能力。因此，研究人员对如何高效整合这两种互补的人工智能流派产生了浓厚的兴趣。他们正致力于探索如何将深度学习的强大表征能力和符号逻辑的精确推理能力相结合，以期创造出更全面、更强大的AI系统。

  

> 如今许多人认为，必须将深度学习与基于符号、逻辑的方法中存在的高级推理能力结合起来，才能向更通用的人工智能系统迈进。

  

虽然深度学习领域对符号的流派兴趣刚刚显现，但在一个名为“神经-符号集成（ Neural-Symbolic Integration, NSI）学习与推理”的领域中，这一主题已经得到了长期深入的研究。

  

传统上，神经科学研究领域一直专注于在神经网络中模拟逻辑推理，为符号和子符号表征与计算之间的对应关系提供了丰富的视角。然而，从历史的角度来看，这个领域主要集中在对应关系和理论模型的表现力分析上，而非实际学习应用。这可能是它们被主流研究边缘化的一个重要原因。

  

但是，随着深度学习概念的最新发展，NSI正迎来前所未有的发展势头。

  

**■2.1 从符号到神经元**

  

令人颇感意外的是，早期符号AI在学术界中一度占据主导地位，神经微积分与逻辑微积分之间的对应关系在历史长河中早已稳固确立。

  

当我们重新审视于1943年发表的机器学习领域开创性论文《A logical calculus of the ideas immanent in nervous activity》时，可以清晰地看到，他们首次提出的计算神经元实际上是受到启发，用以模仿输入（二值）命题的逻辑门。这一前沿思想的基础在于一个核心事实：逻辑连接词能够便捷地通过带权重的二值阈值单元（即感知器）进行编码。

  

![[140928c2dc9648eefe793e826e123ed7_MD5.webp]]

▲图5｜逻辑 AND 和 OR 函数可以简单地用一个阈值神经元（感知器）来表示（来源@Martin Krutsky）©️【深蓝AI】

  

尽管线性感知器在多个领域都取得了显著的成功，但它无法计算逻辑亦或（XOR）函数，这一缺陷限制了线性感知器在表达更复杂逻辑嵌套函数方面的能力。然而，人们很快发现，通过将多个感知器组合在一起，可以克服这一难题，从而扩展其表示能力。

  

遗憾的是，当时缺乏一种有效的学习算法来计算这种“神经网络”的权重，这使得许多研究人员和资方放弃了连结机制的想法。因此，他们转而采用符号法和其他统计方法来探索人工智能的新途径。

  

![[93ab661a45aa51daa8ad1f8c7417e92d_MD5.webp]]

▲图6｜XOR 函数可视为 OR 和 NAND 的复合，只有通过将神经元堆叠成带隐藏层的神经网络才能表示它（来源@Martin Krutsky）©️【深蓝AI】

  

直到20世纪80年代，链式法则才被引入微分嵌套函数中，并被用作反向传播方法，用以计算神经网络的梯度。通过这种方法，研究人员能够利用梯度下降算法对神经网络进行训练。然而，为了实现这一目标，研究人员不得不将最初使用的二值阈值单元替换为可微分的激活函数，如sigmoids。这一变革虽然在技术上取得了成功，但却在神经网络与其原本清晰的逻辑解释之间挖开了一道难以逾越的鸿沟。

  

**■2.2 从逻辑到深度学习**

  

在现代深度学习的背景下，将单个神经元与逻辑连接子之间的相似性相提并论，或许显得有些落后。然而，深度学习的现代理念最初并未局限于神经网络本身。实际上，它更广泛地适用于“分层组合建模方法”，这些方法专注于概念的构建和复用。这些概念在目标变量的不同推理路径中被反复利用，构成了深度学习的基础。

  

尽管在深度学习中，这些概念通常是通过隐藏神经元/层的计算来实例化的，但这种分层抽象的方式在人类思维和逻辑推理中同样十分常见。

  

因此，虽然抽象的层次通常由神经网络的隐藏层呈现，但也可以将其视为 "重复许多子公式构成的复杂命题式"。

  

在90年代期间，众多NSI系统纷纷涌现，它们以鲜明的方式展示了逻辑推理的层次结构与经典神经网络之间的紧密联系。其中，基于知识的人工神经网络（Knowledge-Based Artificial Neural Network, KBANN）便是这一趋势的代表。

  

![[14ceb8340964d6a802254eadb6e66f7a_MD5.webp]]

▲图7｜KBANN 方法的示例：(a) 命题规则集；(b) 作为 AND-OR 关系图的规则；每个命题表示为一个单元（还添加了额外的单元来表示互不相关的定义），(c) 设置其权重和偏置以实现 AND 或 OR 门，例如，b->a 和 c->a 的权重设为 4，单元 a 的偏置（阈值）设为 -6；（d）层与层之间添加低权重链接，作为未来学习的基础（来源@Richard Maclin）©️【深蓝AI】

  

KBANN，作为一种独特的混合学习系统，根植于联结机制学习技术的深厚基础。它巧妙地将命题逻辑程序所表征的特定问题“域理论”映射到前馈神经网络之中。随后，KBANN利用反向传播算法对这些重新表述的知识进行调整和优化。

  

这个想法后来得到了进一步的拓展，通过开发相应的算法，使得可以从学习网络中提取符号知识。这一突破性的进展完成了NSI界所称的“神经-符号学习循环”。

  

![[fb7d478f5bd6e2258954093047920b79_MD5.webp]]

▲图8｜神经-符号学习循环的概念。首先，利用数据（D）创建或学习（P）一个符号模型（S）。然后将其转化（R）为神经网络（N），在此基础上进行结构（T）和权重（W）学习改进，最后提取符号模型（E）。然后继续循环，迭代改进模型（来源@Martin Svatos）©️【深蓝AI】

  

然而，神经与符号之间的直接对应关系在命题逻辑环境中遇到了难以逾越的限制。由于缺乏关系逻辑表征的能力，这种对抽象知识和复杂现实问题的建模显得捉襟见肘。因此，命题神经-符号集成研究至今仍局限于一个小众领域。

  

**■2.3 NSI 的关系表征局限**

  

尽管命题逻辑公式与神经网络之间的映射关系清晰明了，但实现这种映射却一直是神经科学研究领域的一大挑战。在命题逻辑中，变化的仅仅是输入命题的二值，而逻辑程序的结构则保持固定。

  

这种关系很容易让人将神经网络视为布尔线路，将命题解释视为特征向量。然而，在关系逻辑中，输入解释不再局限于固定数量的独立命题值，而是变成了在特定世界中存在的相关事实的无约束集合。因此，这种逻辑推理结构无法简单地通过固定的布尔线路来表示。

  

核心难题在于，如何将可能无限变化的关系推理结构有效地编码为神经网络的有限固定结构。John McCarthy将这种神经网络无法捕捉命题表达能力之外逻辑推理的现象称为“命题固定化”。

  

**■2.4 NSI 发展趋势**

  

在现代深度学习中，基于动态计算图的新型神经架构逐渐崭露头角，特别在处理序列、集合和树等（非命题）结构化数据时表现出色。最近，图神经网络（Graph neural network, GNN）的扩展也开始受到广泛关注，尤其是在处理任意（不规则）图方面。

  

这些动态模型摒弃了将关系表征（如关系逻辑程序的解释）转化为固定张量格式的预处理步骤。相反，它们通过灵活调整神经模型的结构来直接反映输入数据结构的变化，同时采用共享参数方案来体现各自模型的先验知识。

  

尽管目前引入的特定动态深度学习模型（如GNNs）主要基于特定的图传播启发式推理方法，尚未达到通用推理器的水平，但动态神经计算的范式为神经网络中正确反映关系逻辑推理提供了可能性，与经典的命题式NSI（如KBANN）精神相契合。这一发展预示着未来神经网络在逻辑推理领域的更大潜力。

  

参考：

_Besold, Tarek R., et al. “Neural-symbolic learning and reasoning: A survey and interpretation.” arXiv preprint arXiv:1711.03902 (2017)._

_Martin, Krutský. Exploring symmetries in deep learning. BSc thesis. Czech Technical University in Prague, 2021._

_Towell, Geoffrey G., and Jude W. Shavlik. “Knowledge-based artificial neural networks.” Artificial intelligence 70.1–2 (1994): 119–165._

_Maclin, Richard F. Learning from instruction and experience: Methods for incorporating procedural domain theories into knowledge-based neural networks. University of Wisconsin-Madison Department of Computer Sciences, 1995._

_https://medium.com/towards-data-science/what-is-relational-machine-learning-afbe4a9c4231_

_https://medium.com/towards-data-science/what-is-neural-symbolic-integration-d5c6267dfdb0_

_https://medium.com/towards-nesy/write-for-towards-nesy-27caa07e9b81_

---


